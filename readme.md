# ğŸ§  Reinforcement Learning for Classic Control Environments

This repository provides an implementation of reinforcement learning algorithmsâ€”**Dueling DQN** and **Monte Carlo REINFORCE**â€”to solve classic control environments such as **CartPole** and **Acrobot** using PyTorch.

## ğŸš€ Features

- Support for **Dueling Deep Q-Network (Dueling DQN)**
- Support for **Monte Carlo REINFORCE**
- Replay buffer for experience replay
- Target network updates
- Customizable training hyperparameters

## ğŸ“¦ Dependencies

- Python 3.7+
- PyTorch
- NumPy
- OpenAI Gym
- argparse

Install dependencies:


### ğŸ§¾ Command Line Arguments


| ğŸ·ï¸ **Argument**       | âœ‚ï¸ **Short Name** | ğŸ”¢ **Type**   | âš™ï¸ **Default Value**  | ğŸ“ **Description**                                                                 |
|------------------------|-------------------|---------------|------------------------|------------------------------------------------------------------------------------|
| `--env`               | `-env`           | `str`         | `'cartpole'`          | ğŸŒ Choices of environment: `acrobot`.                                             |
| `--algorithm`         | `-a`             | `str`         | `'dueling_dqn'`       | ğŸ§  Choices of algorithm: `dueling_dqn`, `mc_reinforce`.                           |
| `--use_max`           | `-um`            | `bool`        | `False`               | ğŸ“ˆ Use the max to constrain the advantage function.                               |
| `--buffer_size`       | `-bs`            | `int`         | `1e5`                 | ğŸ—‚ï¸ Size of the replay buffer.                                                     |
| `--learning_rate`     | `-lr`            | `float`       | `1e-4`                | âš¡ Learning rate for the optimizer.                                               |
| `--value_learning_rate` | `-vlr`         | `float`       | `1e-3`                | ğŸ“Š Learning rate for the value optimizer.                                         |
| `--batch_size`        | `-b`             | `int`         | `128`                 | ğŸ“¦ Batch size.                                                                    |
| `--gamma`             | `-g`             | `float`       | `0.99`                | ğŸ”„ Gamma value used for discounting.                                              |
| `--update_period`     | `-up`            | `int`         | `4`                   | â³ Time period for updating the target network parameters.                        |
| `--use_baseline`      | `-ub`            | `bool`        | `False`               | ğŸ§® Use baseline for Monte Carlo REINFORCE.                                        |


### ğŸ§ª Example

```bash
python main.py -env acrobot -a mc_reinforce -lr 1e-3 -ub True
```