{'env': 'cartpole', 'algorithm': 'mc_reinforce', 'use_max': False, 'buffer_size': 100000, 'learning_rate': 0.01, 'value_learning_rate': 0.001, 'batch_size': 128, 'gamma': 0.99, 'update_period': 4, 'use_baseline': False, 'wandb_sweep': False, 'sweep_id': None, 'wandb_entity': 'da24d008-iit-madras', 'wandb_project': 'rl-assignment-2'}
Episode 100	Average Return: 18.99
Episode 200	Average Return: 20.92
Episode 300	Average Return: 22.90
Episode 400	Average Return: 23.51
Episode 500	Average Return: 23.37
Episode 600	Average Return: 22.04
Episode 700	Average Return: 23.30
Episode 799	Average Return: 22.28
Traceback (most recent call last):
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to RL DA6400/assignment2/main.py", line 35, in train
    train_fn(env, rl_agent, wandb)
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to RL DA6400/assignment2/trainer.py", line 62, in mc_trainer
    action = agent.act(state)
             ^^^^^^^^^^^^^^^^
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to RL DA6400/assignment2/agent.py", line 108, in act
    m = Categorical(probs)
        ^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/rl_env/lib/python3.11/site-packages/torch/distributions/categorical.py", line 70, in __init__
    super().__init__(batch_shape, validate_args=validate_args)
  File "/opt/anaconda3/envs/rl_env/lib/python3.11/site-packages/torch/distributions/distribution.py", line 66, in __init__
    valid = constraint.check(value)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/rl_env/lib/python3.11/site-packages/torch/distributions/constraints.py", line 440, in check
    return torch.all(value >= 0, dim=-1) & ((value.sum(-1) - 1).abs() < 1e-6)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
