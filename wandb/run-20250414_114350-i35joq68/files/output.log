{'env': 'cartpole', 'algorithm': 'mc_reinforce', 'use_max': False, 'buffer_size': 100000, 'learning_rate': 0.00020092764651836285, 'value_learning_rate': 0.001, 'batch_size': 256, 'gamma': 0.99, 'update_period': 4, 'use_baseline': False, 'wandb_sweep': False, 'sweep_id': None, 'wandb_entity': 'da24d008-iit-madras', 'wandb_project': 'rl-assignment-2'}
Episode 100	Average Return: 21.48
Episode 200	Average Return: 21.97
Episode 300	Average Return: 19.46
Episode 400	Average Return: 23.12
Episode 500	Average Return: 23.47
Episode 600	Average Return: 21.28
Episode 700	Average Return: 23.25
Episode 800	Average Return: 22.64
Episode 900	Average Return: 21.74
Episode 1000	Average Return: 20.96
Episode 1100	Average Return: 23.70
Episode 1200	Average Return: 22.25
Episode 1300	Average Return: 20.77
Episode 1400	Average Return: 20.62
Episode 1500	Average Return: 22.52
Episode 1600	Average Return: 22.36
Episode 1700	Average Return: 23.00
Episode 1800	Average Return: 22.05
Episode 1900	Average Return: 23.03
Episode 1965	Average Return: 20.71
Traceback (most recent call last):
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to RL DA6400/assignment2/main.py", line 35, in train
    train_fn(env, rl_agent, wandb)
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to RL DA6400/assignment2/trainer.py", line 74, in mc_trainer
    agent.update_policy()
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to RL DA6400/assignment2/agent.py", line 142, in update_policy
    policy_loss.backward()
  File "/opt/anaconda3/envs/rl_env/lib/python3.11/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/opt/anaconda3/envs/rl_env/lib/python3.11/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
