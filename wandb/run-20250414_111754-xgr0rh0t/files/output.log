{'env': 'cartpole', 'algorithm': 'mc_reinforce', 'use_max': False, 'buffer_size': 100000, 'learning_rate': 0.0001, 'value_learning_rate': 0.001, 'batch_size': 128, 'gamma': 0.99, 'update_period': 4, 'use_baseline': False, 'wandb_sweep': False, 'sweep_id': None, 'wandb_entity': 'da24d008-iit-madras', 'wandb_project': 'rl-assignment-2'}
Episode 100	Average Return: 16.42
Episode 200	Average Return: 17.81
Episode 300	Average Return: 20.57
Episode 393	Average Return: 18.80
Traceback (most recent call last):
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to RL DA6400/assignment2/main.py", line 35, in train
    train_fn(env, rl_agent, wandb)
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to RL DA6400/assignment2/trainer.py", line 74, in mc_trainer
    agent.update_policy()
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to RL DA6400/assignment2/agent.py", line 148, in update_policy
    self.policy_optimizer.step()
  File "/opt/anaconda3/envs/rl_env/lib/python3.11/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/rl_env/lib/python3.11/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/rl_env/lib/python3.11/site-packages/torch/optim/adam.py", line 166, in step
    adam(
  File "/opt/anaconda3/envs/rl_env/lib/python3.11/site-packages/torch/optim/adam.py", line 316, in adam
    func(params,
  File "/opt/anaconda3/envs/rl_env/lib/python3.11/site-packages/torch/optim/adam.py", line 391, in _single_tensor_adam
    exp_avg.lerp_(grad, 1 - beta1)
KeyboardInterrupt
