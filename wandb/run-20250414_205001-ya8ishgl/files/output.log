{'env': 'cartpole', 'algorithm': 'dueling_dqn', 'use_max': True, 'buffer_size': 100000, 'learning_rate': 0.0001, 'value_learning_rate': 0.001, 'batch_size': 128, 'gamma': 0.99, 'update_period': 4, 'use_baseline': False, 'wandb_sweep': False, 'sweep_id': None, 'wandb_entity': 'da24d008-iit-madras', 'wandb_project': 'rl-pa2'}
Episode 35	Average Score: 28.91
Traceback (most recent call last):
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to RL DA6400/assignment2/main.py", line 39, in train
    train_fn(env, rl_agent, wandb)
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to RL DA6400/assignment2/trainer.py", line 30, in dueling_trainer
    agent.step(state, action, reward, next_state, done)
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to RL DA6400/assignment2/agent.py", line 53, in step
    experiences = self.buffer.sample(self.batch_size)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/rudra_sarkar/Documents/PhD IIT Madras/Intro to RL DA6400/assignment2/replay_buffer.py", line 22, in sample
    rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in vstack
  File "/opt/anaconda3/envs/rl_env/lib/python3.11/site-packages/numpy/core/shape_base.py", line 293, in vstack
    arrs = atleast_2d(*tup)
           ^^^^^^^^^^^^^^^^
  File "<__array_function__ internals>", line 200, in atleast_2d
  File "/opt/anaconda3/envs/rl_env/lib/python3.11/site-packages/numpy/core/shape_base.py", line 123, in atleast_2d
    result = ary.reshape(1, 1)
             ^^^^^^^^^^^^^^^^^
KeyboardInterrupt
